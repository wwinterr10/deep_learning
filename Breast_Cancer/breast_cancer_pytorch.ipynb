{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19df5cff-68df-40ca-b67a-90ed3e2a3f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install scikit-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b81158f-91f9-44f7-b7f2-791af898112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pandas -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edd1cc0-6ab5-43f2-a992-13e63f11c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ebc423-bb49-49cf-ba99-ddf0587bb3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 569\\n\\n:Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n:Attribute Information:\\n    - radius (mean of distances from center to points on the perimeter)\\n    - texture (standard deviation of gray-scale values)\\n    - perimeter\\n    - area\\n    - smoothness (local variation in radius lengths)\\n    - compactness (perimeter^2 / area - 1.0)\\n    - concavity (severity of concave portions of the contour)\\n    - concave points (number of concave portions of the contour)\\n    - symmetry\\n    - fractal dimension (\"coastline approximation\" - 1)\\n\\n    The mean, standard error, and \"worst\" or largest (mean of the three\\n    worst/largest values) of these features were computed for each image,\\n    resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n    10 is Radius SE, field 20 is Worst Radius.\\n\\n    - class:\\n            - WDBC-Malignant\\n            - WDBC-Benign\\n\\n:Summary Statistics:\\n\\n===================================== ====== ======\\n                                        Min    Max\\n===================================== ====== ======\\nradius (mean):                        6.981  28.11\\ntexture (mean):                       9.71   39.28\\nperimeter (mean):                     43.79  188.5\\narea (mean):                          143.5  2501.0\\nsmoothness (mean):                    0.053  0.163\\ncompactness (mean):                   0.019  0.345\\nconcavity (mean):                     0.0    0.427\\nconcave points (mean):                0.0    0.201\\nsymmetry (mean):                      0.106  0.304\\nfractal dimension (mean):             0.05   0.097\\nradius (standard error):              0.112  2.873\\ntexture (standard error):             0.36   4.885\\nperimeter (standard error):           0.757  21.98\\narea (standard error):                6.802  542.2\\nsmoothness (standard error):          0.002  0.031\\ncompactness (standard error):         0.002  0.135\\nconcavity (standard error):           0.0    0.396\\nconcave points (standard error):      0.0    0.053\\nsymmetry (standard error):            0.008  0.079\\nfractal dimension (standard error):   0.001  0.03\\nradius (worst):                       7.93   36.04\\ntexture (worst):                      12.02  49.54\\nperimeter (worst):                    50.41  251.2\\narea (worst):                         185.2  4254.0\\nsmoothness (worst):                   0.071  0.223\\ncompactness (worst):                  0.027  1.058\\nconcavity (worst):                    0.0    1.252\\nconcave points (worst):               0.0    0.291\\nsymmetry (worst):                     0.156  0.664\\nfractal dimension (worst):            0.055  0.208\\n===================================== ====== ======\\n\\n:Missing Attribute Values: None\\n\\n:Class Distribution: 212 - Malignant, 357 - Benign\\n\\n:Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n:Donor: Nick Street\\n\\n:Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. dropdown:: References\\n\\n  - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\\n    for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\\n    Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n    San Jose, CA, 1993.\\n  - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\\n    prognosis via linear programming. Operations Research, 43(4), pages 570-577,\\n    July-August 1995.\\n  - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n    to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\\n    163-171.\\n',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위스콘신 유방암 데이터를 읽어서 data에 저장\n",
    "data = datasets.load_breast_cancer()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38125564-f84b-4b25-bf0b-c8d36c6dfcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유방암 판단의 독립변수를 읽어서 X에 저장\n",
    "X = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc07b53f-c641-43e6-a4c2-4e544a402f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유방암 데이터의 종속 변수\n",
    "#악성이면 0, 양성이면 1\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3659d874-885b-4a7c-a1f2-4c31cb790ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1차원 배열을 2차원 배열로 변환\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8ac253-980a-4254-8570-2e5f3212e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y를 8:2로 나누어 80%는 훈련용 데이터로, 20%는 테스트 데이터로 설정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=778)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c7a944-ca83-4c4d-9515-37ffca30f84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#X에서 평균을 빼고 표준편차로 나눠서 평균: 0, 표준편차: 1로 변환할 객체\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#X_train의 평균과 표준편차를 계산\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ed11587-0261-48a0-bc75-d201c24fc922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14990291,  1.10898417,  0.11541217, ..., -0.67987109,\n",
       "        -0.60275672, -0.62966586],\n",
       "       [-0.48116721, -1.51562012, -0.55007951, ..., -1.32531438,\n",
       "        -0.97405071, -0.74664893],\n",
       "       [ 1.13448917, -2.09026539,  1.30898459, ...,  2.28468958,\n",
       "         2.58699616,  1.86239541],\n",
       "       ...,\n",
       "       [-0.26204564,  1.39747955, -0.32726241, ..., -0.82224384,\n",
       "        -0.72242999, -0.87543762],\n",
       "       [ 0.39531907,  1.09256574,  0.50565919, ...,  1.54180947,\n",
       "         0.15057116,  1.20771953],\n",
       "       [-0.73242661, -0.21856367, -0.75936691, ..., -0.47682728,\n",
       "         0.45282287, -0.29857159]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train에서 평균을 빼고 표준편차로 나누어 X_train에 대입\n",
    "X_train = scaler.transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e486106e-5bd2-4576-8184-ff8750aaef73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45779424, -0.69704381, -0.44776122, ..., -0.45821745,\n",
       "         0.36843788, -0.47297295],\n",
       "       [ 1.86197278,  0.50853851,  1.71910335, ...,  0.4554797 ,\n",
       "        -1.03849016, -0.69352359],\n",
       "       [-0.59511043, -1.37254518, -0.59235979, ..., -0.61224025,\n",
       "        -0.2053801 , -0.19715049],\n",
       "       ...,\n",
       "       [-0.29126185, -0.87530111, -0.19577073, ...,  1.27400951,\n",
       "         0.3561637 ,  3.02149367],\n",
       "       [-0.17439701, -0.09425265, -0.15814127, ...,  0.46758365,\n",
       "        -0.38182146, -0.39355325],\n",
       "       [-0.91941035, -0.39212999, -0.89001299, ..., -0.2388333 ,\n",
       "        -0.96024225, -0.07587447]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test에서 X_train의 평균을 빼고 X_train의 표준편차로 나누어 X_test에 대입\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ca546a-03c7-425e-b317-3d55e4ffe48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.6784e-19],\n",
       "        [ 8.9683e-43],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00],\n",
       "        [ 0.0000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#유방암 데이터를 계산하기 위한 w 생성\n",
    "#torch.empty(30, 1): 30행 1열의 tensor 배열 리턴\n",
    "w = torch.empty(30, 1)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aba750a-0e7a-404e-aacc-9205042cf652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4080],\n",
       "        [-0.0414],\n",
       "        [ 0.2634],\n",
       "        [-0.1662],\n",
       "        [ 0.3745],\n",
       "        [-0.2526],\n",
       "        [ 0.0882],\n",
       "        [ 0.1147],\n",
       "        [ 0.0383],\n",
       "        [-0.0756],\n",
       "        [-0.0158],\n",
       "        [-0.0071],\n",
       "        [ 0.3712],\n",
       "        [ 0.0911],\n",
       "        [ 0.3617],\n",
       "        [-0.0270],\n",
       "        [ 0.2358],\n",
       "        [-0.2102],\n",
       "        [-0.2852],\n",
       "        [-0.4146],\n",
       "        [-0.1412],\n",
       "        [-0.2717],\n",
       "        [-0.3318],\n",
       "        [ 0.0795],\n",
       "        [ 0.3689],\n",
       "        [-0.2191],\n",
       "        [ 0.3045],\n",
       "        [-0.2887],\n",
       "        [ 0.2930],\n",
       "        [-0.2561]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#w를 어떻게 초기화해야 빠르게 cost가 0에 수렴하는가?\n",
    "#참고: https://www.youtube.com/watch?v=4rC0sWrp3Uw\n",
    "#w에 학습이 잘되도록 값을 대입(xavier initialization)\n",
    "\n",
    "w = torch.nn.init.xavier_uniform_(w)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf9daa10-a6f7-440d-992c-2d2fba96e57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18204\\3206577545.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  w = torch.tensor(w, requires_grad = True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4080],\n",
       "        [-0.0414],\n",
       "        [ 0.2634],\n",
       "        [-0.1662],\n",
       "        [ 0.3745],\n",
       "        [-0.2526],\n",
       "        [ 0.0882],\n",
       "        [ 0.1147],\n",
       "        [ 0.0383],\n",
       "        [-0.0756],\n",
       "        [-0.0158],\n",
       "        [-0.0071],\n",
       "        [ 0.3712],\n",
       "        [ 0.0911],\n",
       "        [ 0.3617],\n",
       "        [-0.0270],\n",
       "        [ 0.2358],\n",
       "        [-0.2102],\n",
       "        [-0.2852],\n",
       "        [-0.4146],\n",
       "        [-0.1412],\n",
       "        [-0.2717],\n",
       "        [-0.3318],\n",
       "        [ 0.0795],\n",
       "        [ 0.3689],\n",
       "        [-0.2191],\n",
       "        [ 0.3045],\n",
       "        [-0.2887],\n",
       "        [ 0.2930],\n",
       "        [-0.2561]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#곱해지는 값 w를 초기화\n",
    "#학습을 통해 값이 변경되는 변수임을 명시(requires_grad = True)\n",
    "w = torch.tensor(w, requires_grad = True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "050523e1-bd42-493e-9524-0a49ec5943c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#더해지는 값 b는 0으로 초기화(torch.tensor([0.0])\n",
    "#학습을 통해 값이 변경되는 변수임을 명시(requires_grad = True)\n",
    "b = torch.tensor([0.0], requires_grad = True)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cee63a26-a869-4af4-af68-d8afb3c0c6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1499,  1.1090,  0.1154,  ..., -0.6799, -0.6028, -0.6297],\n",
       "        [-0.4812, -1.5156, -0.5501,  ..., -1.3253, -0.9741, -0.7466],\n",
       "        [ 1.1345, -2.0903,  1.3090,  ...,  2.2847,  2.5870,  1.8624],\n",
       "        ...,\n",
       "        [-0.2620,  1.3975, -0.3273,  ..., -0.8222, -0.7224, -0.8754],\n",
       "        [ 0.3953,  1.0926,  0.5057,  ...,  1.5418,  0.1506,  1.2077],\n",
       "        [-0.7324, -0.2186, -0.7594,  ..., -0.4768,  0.4528, -0.2986]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train을 float 타입 tensor로 변환\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c81a82d-4b95-4d3d-9658-8b41e07b7fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4578, -0.6970, -0.4478,  ..., -0.4582,  0.3684, -0.4730],\n",
       "        [ 1.8620,  0.5085,  1.7191,  ...,  0.4555, -1.0385, -0.6935],\n",
       "        [-0.5951, -1.3725, -0.5924,  ..., -0.6122, -0.2054, -0.1972],\n",
       "        ...,\n",
       "        [-0.2913, -0.8753, -0.1958,  ...,  1.2740,  0.3562,  3.0215],\n",
       "        [-0.1744, -0.0943, -0.1581,  ...,  0.4676, -0.3818, -0.3936],\n",
       "        [-0.9194, -0.3921, -0.8900,  ..., -0.2388, -0.9602, -0.0759]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test를 float 타입 tensor로 변환\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f44cb765-1f6c-4fda-af9e-fe6956b8a994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train을 float 타입 tensor로 변환\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7e2a505-7637-49d1-bc8c-38d1500219c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test를 float 타입 tensor로 변환\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd106fce-d324-423b-b26a-af9024d26f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2780],\n",
       "        [0.4313],\n",
       "        [0.5603],\n",
       "        [0.3216],\n",
       "        [0.7529],\n",
       "        [0.4266],\n",
       "        [0.3056],\n",
       "        [0.5248],\n",
       "        [0.4368],\n",
       "        [0.4343],\n",
       "        [0.8130],\n",
       "        [0.6392],\n",
       "        [0.5042],\n",
       "        [0.0625],\n",
       "        [0.6469],\n",
       "        [0.1290],\n",
       "        [0.7687],\n",
       "        [0.2450],\n",
       "        [0.1630],\n",
       "        [0.1546],\n",
       "        [0.6210],\n",
       "        [0.6886],\n",
       "        [0.8019],\n",
       "        [0.4954],\n",
       "        [0.7717],\n",
       "        [0.3033],\n",
       "        [0.5016],\n",
       "        [0.6973],\n",
       "        [0.4468],\n",
       "        [0.8108],\n",
       "        [0.9118],\n",
       "        [0.4149],\n",
       "        [0.7141],\n",
       "        [0.4732],\n",
       "        [0.5468],\n",
       "        [0.4473],\n",
       "        [0.4083],\n",
       "        [0.3999],\n",
       "        [0.1210],\n",
       "        [0.3840],\n",
       "        [0.7478],\n",
       "        [0.7231],\n",
       "        [0.5740],\n",
       "        [0.4465],\n",
       "        [0.7397],\n",
       "        [0.1505],\n",
       "        [0.3179],\n",
       "        [0.6089],\n",
       "        [0.5856],\n",
       "        [0.5808],\n",
       "        [0.6090],\n",
       "        [0.0402],\n",
       "        [0.3348],\n",
       "        [0.9311],\n",
       "        [0.8302],\n",
       "        [0.4796],\n",
       "        [0.8000],\n",
       "        [0.6318],\n",
       "        [0.3735],\n",
       "        [0.1508],\n",
       "        [0.7045],\n",
       "        [0.3897],\n",
       "        [0.6847],\n",
       "        [0.6112],\n",
       "        [0.8956],\n",
       "        [0.5771],\n",
       "        [0.8815],\n",
       "        [0.4100],\n",
       "        [0.5154],\n",
       "        [0.3783],\n",
       "        [0.3047],\n",
       "        [0.2026],\n",
       "        [0.6676],\n",
       "        [0.8727],\n",
       "        [0.8582],\n",
       "        [0.3206],\n",
       "        [0.2325],\n",
       "        [0.3847],\n",
       "        [0.4367],\n",
       "        [0.1606],\n",
       "        [0.0411],\n",
       "        [0.5526],\n",
       "        [0.8663],\n",
       "        [0.4443],\n",
       "        [0.5308],\n",
       "        [0.6979],\n",
       "        [0.3227],\n",
       "        [0.4913],\n",
       "        [0.5307],\n",
       "        [0.1941],\n",
       "        [0.3547],\n",
       "        [0.7028],\n",
       "        [0.4084],\n",
       "        [0.8506],\n",
       "        [0.5609],\n",
       "        [0.4503],\n",
       "        [0.5884],\n",
       "        [0.4104],\n",
       "        [0.4119],\n",
       "        [0.3643],\n",
       "        [0.1641],\n",
       "        [0.6676],\n",
       "        [0.7211],\n",
       "        [0.1529],\n",
       "        [0.3291],\n",
       "        [0.5685],\n",
       "        [0.5672],\n",
       "        [0.2507],\n",
       "        [0.6911],\n",
       "        [0.4477],\n",
       "        [0.7966],\n",
       "        [0.3515],\n",
       "        [0.4910],\n",
       "        [0.7778],\n",
       "        [0.6250],\n",
       "        [0.6442],\n",
       "        [0.3221],\n",
       "        [0.3003],\n",
       "        [0.5348],\n",
       "        [0.1368],\n",
       "        [0.4316],\n",
       "        [0.6438],\n",
       "        [0.7885],\n",
       "        [0.5843],\n",
       "        [0.8748],\n",
       "        [0.7415],\n",
       "        [0.3331],\n",
       "        [0.6582],\n",
       "        [0.6372],\n",
       "        [0.7924],\n",
       "        [0.7152],\n",
       "        [0.5628],\n",
       "        [0.6989],\n",
       "        [0.4894],\n",
       "        [0.3415],\n",
       "        [0.5758],\n",
       "        [0.6795],\n",
       "        [0.6358],\n",
       "        [0.6884],\n",
       "        [0.2838],\n",
       "        [0.8174],\n",
       "        [0.7289],\n",
       "        [0.3274],\n",
       "        [0.4312],\n",
       "        [0.4213],\n",
       "        [0.6583],\n",
       "        [0.5709],\n",
       "        [0.3236],\n",
       "        [0.3107],\n",
       "        [0.1396],\n",
       "        [0.7743],\n",
       "        [0.4886],\n",
       "        [0.4367],\n",
       "        [0.9034],\n",
       "        [0.5901],\n",
       "        [0.2447],\n",
       "        [0.1531],\n",
       "        [0.8199],\n",
       "        [0.5863],\n",
       "        [0.4841],\n",
       "        [0.8003],\n",
       "        [0.5148],\n",
       "        [0.7657],\n",
       "        [0.0882],\n",
       "        [0.5950],\n",
       "        [0.3601],\n",
       "        [0.8394],\n",
       "        [0.2044],\n",
       "        [0.5910],\n",
       "        [0.0752],\n",
       "        [0.6375],\n",
       "        [0.5314],\n",
       "        [0.5231],\n",
       "        [0.2106],\n",
       "        [0.4683],\n",
       "        [0.4731],\n",
       "        [0.4494],\n",
       "        [0.7165],\n",
       "        [0.4428],\n",
       "        [0.5278],\n",
       "        [0.4072],\n",
       "        [0.3964],\n",
       "        [0.2056],\n",
       "        [0.7864],\n",
       "        [0.2447],\n",
       "        [0.3711],\n",
       "        [0.4482],\n",
       "        [0.5793],\n",
       "        [0.6785],\n",
       "        [0.8820],\n",
       "        [0.9282],\n",
       "        [0.9602],\n",
       "        [0.2915],\n",
       "        [0.7731],\n",
       "        [0.6027],\n",
       "        [0.6369],\n",
       "        [0.0683],\n",
       "        [0.3112],\n",
       "        [0.5609],\n",
       "        [0.4133],\n",
       "        [0.2189],\n",
       "        [0.3810],\n",
       "        [0.3316],\n",
       "        [0.6208],\n",
       "        [0.4914],\n",
       "        [0.5660],\n",
       "        [0.1836],\n",
       "        [0.3300],\n",
       "        [0.5624],\n",
       "        [0.7898],\n",
       "        [0.5184],\n",
       "        [0.8186],\n",
       "        [0.5739],\n",
       "        [0.4961],\n",
       "        [0.3860],\n",
       "        [0.5263],\n",
       "        [0.2394],\n",
       "        [0.6465],\n",
       "        [0.3009],\n",
       "        [0.8104],\n",
       "        [0.6082],\n",
       "        [0.6475],\n",
       "        [0.0669],\n",
       "        [0.4290],\n",
       "        [0.2025],\n",
       "        [0.1339],\n",
       "        [0.5577],\n",
       "        [0.8069],\n",
       "        [0.5387],\n",
       "        [0.7390],\n",
       "        [0.6390],\n",
       "        [0.3161],\n",
       "        [0.6156],\n",
       "        [0.7546],\n",
       "        [0.6495],\n",
       "        [0.8068],\n",
       "        [0.6725],\n",
       "        [0.3302],\n",
       "        [0.8739],\n",
       "        [0.2912],\n",
       "        [0.4967],\n",
       "        [0.5931],\n",
       "        [0.2202],\n",
       "        [0.7190],\n",
       "        [0.3101],\n",
       "        [0.3235],\n",
       "        [0.5407],\n",
       "        [0.4287],\n",
       "        [0.8290],\n",
       "        [0.5117],\n",
       "        [0.6080],\n",
       "        [0.2200],\n",
       "        [0.7070],\n",
       "        [0.3050],\n",
       "        [0.1647],\n",
       "        [0.5882],\n",
       "        [0.7112],\n",
       "        [0.7207],\n",
       "        [0.1322],\n",
       "        [0.7929],\n",
       "        [0.4572],\n",
       "        [0.4565],\n",
       "        [0.5318],\n",
       "        [0.1700],\n",
       "        [0.3500],\n",
       "        [0.4524],\n",
       "        [0.4186],\n",
       "        [0.4619],\n",
       "        [0.5400],\n",
       "        [0.4985],\n",
       "        [0.6140],\n",
       "        [0.5000],\n",
       "        [0.4552],\n",
       "        [0.5251],\n",
       "        [0.1784],\n",
       "        [0.2772],\n",
       "        [0.5408],\n",
       "        [0.5899],\n",
       "        [0.3007],\n",
       "        [0.5904],\n",
       "        [0.4282],\n",
       "        [0.7449],\n",
       "        [0.5496],\n",
       "        [0.5057],\n",
       "        [0.5214],\n",
       "        [0.1817],\n",
       "        [0.3885],\n",
       "        [0.7158],\n",
       "        [0.7646],\n",
       "        [0.5206],\n",
       "        [0.5867],\n",
       "        [0.4859],\n",
       "        [0.8351],\n",
       "        [0.5465],\n",
       "        [0.7564],\n",
       "        [0.2984],\n",
       "        [0.5680],\n",
       "        [0.5539],\n",
       "        [0.2416],\n",
       "        [0.2930],\n",
       "        [0.4991],\n",
       "        [0.6848],\n",
       "        [0.0597],\n",
       "        [0.8603],\n",
       "        [0.5394],\n",
       "        [0.7943],\n",
       "        [0.1246],\n",
       "        [0.3912],\n",
       "        [0.5774],\n",
       "        [0.3119],\n",
       "        [0.4727],\n",
       "        [0.5350],\n",
       "        [0.7126],\n",
       "        [0.4797],\n",
       "        [0.6985],\n",
       "        [0.1746],\n",
       "        [0.8134],\n",
       "        [0.7196],\n",
       "        [0.3054],\n",
       "        [0.4937],\n",
       "        [0.5850],\n",
       "        [0.3865],\n",
       "        [0.4454],\n",
       "        [0.5211],\n",
       "        [0.2714],\n",
       "        [0.4674],\n",
       "        [0.5765],\n",
       "        [0.6242],\n",
       "        [0.3681],\n",
       "        [0.4617],\n",
       "        [0.5936],\n",
       "        [0.3358],\n",
       "        [0.4215],\n",
       "        [0.4569],\n",
       "        [0.2814],\n",
       "        [0.3948],\n",
       "        [0.4907],\n",
       "        [0.3406],\n",
       "        [0.3036],\n",
       "        [0.3117],\n",
       "        [0.6523],\n",
       "        [0.2930],\n",
       "        [0.8875],\n",
       "        [0.4980],\n",
       "        [0.1743],\n",
       "        [0.2444],\n",
       "        [0.5275],\n",
       "        [0.2353],\n",
       "        [0.3979],\n",
       "        [0.4431],\n",
       "        [0.6600],\n",
       "        [0.6690],\n",
       "        [0.3302],\n",
       "        [0.3220],\n",
       "        [0.5691],\n",
       "        [0.0883],\n",
       "        [0.2446],\n",
       "        [0.4035],\n",
       "        [0.5653],\n",
       "        [0.7422],\n",
       "        [0.4133],\n",
       "        [0.7795],\n",
       "        [0.3762],\n",
       "        [0.5778],\n",
       "        [0.7038],\n",
       "        [0.4647],\n",
       "        [0.4076],\n",
       "        [0.4954],\n",
       "        [0.5340],\n",
       "        [0.6569],\n",
       "        [0.6045],\n",
       "        [0.4916],\n",
       "        [0.5414],\n",
       "        [0.5960],\n",
       "        [0.2965],\n",
       "        [0.4856],\n",
       "        [0.4524],\n",
       "        [0.2344],\n",
       "        [0.4191],\n",
       "        [0.8246],\n",
       "        [0.5396],\n",
       "        [0.5026],\n",
       "        [0.2744],\n",
       "        [0.5523],\n",
       "        [0.2824],\n",
       "        [0.6554],\n",
       "        [0.2776],\n",
       "        [0.6877],\n",
       "        [0.2887],\n",
       "        [0.8306],\n",
       "        [0.4544],\n",
       "        [0.2426],\n",
       "        [0.5295],\n",
       "        [0.3870],\n",
       "        [0.5998],\n",
       "        [0.4530],\n",
       "        [0.6554],\n",
       "        [0.8561],\n",
       "        [0.7350],\n",
       "        [0.9197],\n",
       "        [0.2724],\n",
       "        [0.6402],\n",
       "        [0.4466],\n",
       "        [0.4402],\n",
       "        [0.4220],\n",
       "        [0.5021],\n",
       "        [0.7688],\n",
       "        [0.5307],\n",
       "        [0.5179],\n",
       "        [0.2806],\n",
       "        [0.3928],\n",
       "        [0.0919],\n",
       "        [0.5883],\n",
       "        [0.3529],\n",
       "        [0.9121],\n",
       "        [0.5724],\n",
       "        [0.7664],\n",
       "        [0.7420],\n",
       "        [0.2800],\n",
       "        [0.2983],\n",
       "        [0.3518],\n",
       "        [0.6432],\n",
       "        [0.6491],\n",
       "        [0.4849],\n",
       "        [0.6600],\n",
       "        [0.1206],\n",
       "        [0.5403],\n",
       "        [0.6616],\n",
       "        [0.4631],\n",
       "        [0.3567],\n",
       "        [0.2563],\n",
       "        [0.6350],\n",
       "        [0.3224],\n",
       "        [0.4727],\n",
       "        [0.2854],\n",
       "        [0.1812],\n",
       "        [0.6820],\n",
       "        [0.3265],\n",
       "        [0.2053],\n",
       "        [0.2262],\n",
       "        [0.8639],\n",
       "        [0.5083],\n",
       "        [0.4270],\n",
       "        [0.4984],\n",
       "        [0.4795],\n",
       "        [0.3989],\n",
       "        [0.4878],\n",
       "        [0.3744],\n",
       "        [0.4780],\n",
       "        [0.5340],\n",
       "        [0.6423],\n",
       "        [0.8513],\n",
       "        [0.5229],\n",
       "        [0.3832],\n",
       "        [0.6351]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#배열 X_train과 w를 곱하고 b를 더한 값을 시그모이드를 이용하여 0 ~ 1사이 값 리턴\n",
    "hypothesis = torch.sigmoid(torch.matmul(X_train, w) + b)\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ec8328e-986e-44c4-b62c-feb33bcfecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#미분을 자동 계산해서 w, b를 수정할 객체 생성\n",
    "#learning_rate는 0.01로 설정\n",
    "optimizer = optim.Adam([w, b], lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6deecc1-19ed-4e87-abcc-3e25899c86d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n",
      "w= tensor([[-0.4080],\n",
      "        [-0.0414],\n",
      "        [ 0.2634]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.], requires_grad=True)\n",
      "cost= tensor(0.6527, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 1\n",
      "w= tensor([[-0.4180],\n",
      "        [-0.0514],\n",
      "        [ 0.2534]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.0100], requires_grad=True)\n",
      "cost= tensor(0.5978, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 2\n",
      "w= tensor([[-0.4280],\n",
      "        [-0.0614],\n",
      "        [ 0.2434]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.0200], requires_grad=True)\n",
      "cost= tensor(0.5494, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 3\n",
      "w= tensor([[-0.4379],\n",
      "        [-0.0713],\n",
      "        [ 0.2335]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.0300], requires_grad=True)\n",
      "cost= tensor(0.5071, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 4\n",
      "w= tensor([[-0.4477],\n",
      "        [-0.0811],\n",
      "        [ 0.2237]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.0399], requires_grad=True)\n",
      "cost= tensor(0.4701, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 5\n",
      "w= tensor([[-0.4574],\n",
      "        [-0.0907],\n",
      "        [ 0.2141]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.0498], requires_grad=True)\n",
      "cost= tensor(0.4377, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 6\n",
      "w= tensor([[-0.4669],\n",
      "        [-0.1003],\n",
      "        [ 0.2045]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.0597], requires_grad=True)\n",
      "cost= tensor(0.4093, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 7\n",
      "w= tensor([[-0.4763],\n",
      "        [-0.1096],\n",
      "        [ 0.1952]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.0695], requires_grad=True)\n",
      "cost= tensor(0.3841, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 8\n",
      "w= tensor([[-0.4855],\n",
      "        [-0.1188],\n",
      "        [ 0.1860]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.0793], requires_grad=True)\n",
      "cost= tensor(0.3616, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 9\n",
      "w= tensor([[-0.4945],\n",
      "        [-0.1278],\n",
      "        [ 0.1771]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.0889], requires_grad=True)\n",
      "cost= tensor(0.3415, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 10\n",
      "w= tensor([[-0.5033],\n",
      "        [-0.1366],\n",
      "        [ 0.1683]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.0985], requires_grad=True)\n",
      "cost= tensor(0.3233, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 11\n",
      "w= tensor([[-0.5119],\n",
      "        [-0.1453],\n",
      "        [ 0.1597]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1080], requires_grad=True)\n",
      "cost= tensor(0.3069, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 12\n",
      "w= tensor([[-0.5203],\n",
      "        [-0.1537],\n",
      "        [ 0.1514]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1173], requires_grad=True)\n",
      "cost= tensor(0.2919, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 13\n",
      "w= tensor([[-0.5285],\n",
      "        [-0.1619],\n",
      "        [ 0.1433]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1266], requires_grad=True)\n",
      "cost= tensor(0.2782, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 14\n",
      "w= tensor([[-0.5364],\n",
      "        [-0.1699],\n",
      "        [ 0.1354]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1357], requires_grad=True)\n",
      "cost= tensor(0.2657, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 15\n",
      "w= tensor([[-0.5441],\n",
      "        [-0.1778],\n",
      "        [ 0.1278]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1447], requires_grad=True)\n",
      "cost= tensor(0.2542, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 16\n",
      "w= tensor([[-0.5516],\n",
      "        [-0.1854],\n",
      "        [ 0.1204]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1536], requires_grad=True)\n",
      "cost= tensor(0.2437, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 17\n",
      "w= tensor([[-0.5589],\n",
      "        [-0.1929],\n",
      "        [ 0.1132]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1623], requires_grad=True)\n",
      "cost= tensor(0.2340, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 18\n",
      "w= tensor([[-0.5659],\n",
      "        [-0.2001],\n",
      "        [ 0.1063]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1709], requires_grad=True)\n",
      "cost= tensor(0.2251, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 19\n",
      "w= tensor([[-0.5727],\n",
      "        [-0.2072],\n",
      "        [ 0.0996]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1794], requires_grad=True)\n",
      "cost= tensor(0.2168, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 20\n",
      "w= tensor([[-0.5793],\n",
      "        [-0.2141],\n",
      "        [ 0.0931]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1877], requires_grad=True)\n",
      "cost= tensor(0.2093, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 21\n",
      "w= tensor([[-0.5857],\n",
      "        [-0.2208],\n",
      "        [ 0.0869]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.1958], requires_grad=True)\n",
      "cost= tensor(0.2023, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 22\n",
      "w= tensor([[-0.5918],\n",
      "        [-0.2273],\n",
      "        [ 0.0809]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2038], requires_grad=True)\n",
      "cost= tensor(0.1959, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 23\n",
      "w= tensor([[-0.5977],\n",
      "        [-0.2337],\n",
      "        [ 0.0751]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2116], requires_grad=True)\n",
      "cost= tensor(0.1900, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 24\n",
      "w= tensor([[-0.6034],\n",
      "        [-0.2399],\n",
      "        [ 0.0695]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2193], requires_grad=True)\n",
      "cost= tensor(0.1845, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 25\n",
      "w= tensor([[-0.6089],\n",
      "        [-0.2459],\n",
      "        [ 0.0641]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2268], requires_grad=True)\n",
      "cost= tensor(0.1795, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 26\n",
      "w= tensor([[-0.6141],\n",
      "        [-0.2517],\n",
      "        [ 0.0590]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2341], requires_grad=True)\n",
      "cost= tensor(0.1748, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 27\n",
      "w= tensor([[-0.6192],\n",
      "        [-0.2574],\n",
      "        [ 0.0540]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2413], requires_grad=True)\n",
      "cost= tensor(0.1704, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 28\n",
      "w= tensor([[-0.6240],\n",
      "        [-0.2630],\n",
      "        [ 0.0492]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2483], requires_grad=True)\n",
      "cost= tensor(0.1664, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 29\n",
      "w= tensor([[-0.6287],\n",
      "        [-0.2683],\n",
      "        [ 0.0447]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2551], requires_grad=True)\n",
      "cost= tensor(0.1626, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 30\n",
      "w= tensor([[-0.6332],\n",
      "        [-0.2736],\n",
      "        [ 0.0403]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2618], requires_grad=True)\n",
      "cost= tensor(0.1591, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 31\n",
      "w= tensor([[-0.6375],\n",
      "        [-0.2786],\n",
      "        [ 0.0361]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2684], requires_grad=True)\n",
      "cost= tensor(0.1559, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 32\n",
      "w= tensor([[-0.6417],\n",
      "        [-0.2836],\n",
      "        [ 0.0320]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2747], requires_grad=True)\n",
      "cost= tensor(0.1528, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 33\n",
      "w= tensor([[-0.6457],\n",
      "        [-0.2884],\n",
      "        [ 0.0281]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2810], requires_grad=True)\n",
      "cost= tensor(0.1499, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 34\n",
      "w= tensor([[-0.6495],\n",
      "        [-0.2930],\n",
      "        [ 0.0244]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2871], requires_grad=True)\n",
      "cost= tensor(0.1472, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 35\n",
      "w= tensor([[-0.6532],\n",
      "        [-0.2975],\n",
      "        [ 0.0208]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2930], requires_grad=True)\n",
      "cost= tensor(0.1447, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 36\n",
      "w= tensor([[-0.6567],\n",
      "        [-0.3019],\n",
      "        [ 0.0173]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.2988], requires_grad=True)\n",
      "cost= tensor(0.1423, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 37\n",
      "w= tensor([[-0.6601],\n",
      "        [-0.3061],\n",
      "        [ 0.0140]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3044], requires_grad=True)\n",
      "cost= tensor(0.1400, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 38\n",
      "w= tensor([[-0.6634],\n",
      "        [-0.3102],\n",
      "        [ 0.0108]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3100], requires_grad=True)\n",
      "cost= tensor(0.1379, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 39\n",
      "w= tensor([[-0.6666],\n",
      "        [-0.3142],\n",
      "        [ 0.0077]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3153], requires_grad=True)\n",
      "cost= tensor(0.1359, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 40\n",
      "w= tensor([[-0.6696],\n",
      "        [-0.3181],\n",
      "        [ 0.0048]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3206], requires_grad=True)\n",
      "cost= tensor(0.1340, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 41\n",
      "w= tensor([[-0.6726],\n",
      "        [-0.3218],\n",
      "        [ 0.0019]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3257], requires_grad=True)\n",
      "cost= tensor(0.1322, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 42\n",
      "w= tensor([[-0.6754],\n",
      "        [-0.3254],\n",
      "        [-0.0009]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3307], requires_grad=True)\n",
      "cost= tensor(0.1305, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 43\n",
      "w= tensor([[-0.6782],\n",
      "        [-0.3289],\n",
      "        [-0.0035]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3356], requires_grad=True)\n",
      "cost= tensor(0.1289, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 44\n",
      "w= tensor([[-0.6808],\n",
      "        [-0.3323],\n",
      "        [-0.0061]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3404], requires_grad=True)\n",
      "cost= tensor(0.1274, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 45\n",
      "w= tensor([[-0.6834],\n",
      "        [-0.3356],\n",
      "        [-0.0086]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3450], requires_grad=True)\n",
      "cost= tensor(0.1259, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 46\n",
      "w= tensor([[-0.6859],\n",
      "        [-0.3388],\n",
      "        [-0.0110]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3495], requires_grad=True)\n",
      "cost= tensor(0.1245, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 47\n",
      "w= tensor([[-0.6883],\n",
      "        [-0.3419],\n",
      "        [-0.0133]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3540], requires_grad=True)\n",
      "cost= tensor(0.1232, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 48\n",
      "w= tensor([[-0.6906],\n",
      "        [-0.3448],\n",
      "        [-0.0156]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3583], requires_grad=True)\n",
      "cost= tensor(0.1219, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 49\n",
      "w= tensor([[-0.6929],\n",
      "        [-0.3477],\n",
      "        [-0.0178]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3625], requires_grad=True)\n",
      "cost= tensor(0.1207, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 50\n",
      "w= tensor([[-0.6951],\n",
      "        [-0.3505],\n",
      "        [-0.0199]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3666], requires_grad=True)\n",
      "cost= tensor(0.1195, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 51\n",
      "w= tensor([[-0.6972],\n",
      "        [-0.3532],\n",
      "        [-0.0220]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3707], requires_grad=True)\n",
      "cost= tensor(0.1184, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 52\n",
      "w= tensor([[-0.6993],\n",
      "        [-0.3558],\n",
      "        [-0.0240]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3746], requires_grad=True)\n",
      "cost= tensor(0.1173, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 53\n",
      "w= tensor([[-0.7014],\n",
      "        [-0.3583],\n",
      "        [-0.0260]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3785], requires_grad=True)\n",
      "cost= tensor(0.1163, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 54\n",
      "w= tensor([[-0.7033],\n",
      "        [-0.3608],\n",
      "        [-0.0279]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3822], requires_grad=True)\n",
      "cost= tensor(0.1153, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 55\n",
      "w= tensor([[-0.7053],\n",
      "        [-0.3632],\n",
      "        [-0.0298]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3859], requires_grad=True)\n",
      "cost= tensor(0.1144, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 56\n",
      "w= tensor([[-0.7072],\n",
      "        [-0.3655],\n",
      "        [-0.0316]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3895], requires_grad=True)\n",
      "cost= tensor(0.1134, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 57\n",
      "w= tensor([[-0.7090],\n",
      "        [-0.3677],\n",
      "        [-0.0334]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3930], requires_grad=True)\n",
      "cost= tensor(0.1126, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 58\n",
      "w= tensor([[-0.7108],\n",
      "        [-0.3699],\n",
      "        [-0.0351]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3965], requires_grad=True)\n",
      "cost= tensor(0.1117, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 59\n",
      "w= tensor([[-0.7126],\n",
      "        [-0.3720],\n",
      "        [-0.0368]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.3998], requires_grad=True)\n",
      "cost= tensor(0.1109, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 60\n",
      "w= tensor([[-0.7143],\n",
      "        [-0.3741],\n",
      "        [-0.0385]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4031], requires_grad=True)\n",
      "cost= tensor(0.1101, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 61\n",
      "w= tensor([[-0.7160],\n",
      "        [-0.3761],\n",
      "        [-0.0401]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4064], requires_grad=True)\n",
      "cost= tensor(0.1093, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 62\n",
      "w= tensor([[-0.7176],\n",
      "        [-0.3780],\n",
      "        [-0.0417]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4095], requires_grad=True)\n",
      "cost= tensor(0.1085, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 63\n",
      "w= tensor([[-0.7193],\n",
      "        [-0.3799],\n",
      "        [-0.0433]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4126], requires_grad=True)\n",
      "cost= tensor(0.1078, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 64\n",
      "w= tensor([[-0.7209],\n",
      "        [-0.3818],\n",
      "        [-0.0448]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4157], requires_grad=True)\n",
      "cost= tensor(0.1071, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 65\n",
      "w= tensor([[-0.7224],\n",
      "        [-0.3836],\n",
      "        [-0.0463]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4187], requires_grad=True)\n",
      "cost= tensor(0.1064, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 66\n",
      "w= tensor([[-0.7240],\n",
      "        [-0.3854],\n",
      "        [-0.0478]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4216], requires_grad=True)\n",
      "cost= tensor(0.1057, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 67\n",
      "w= tensor([[-0.7255],\n",
      "        [-0.3872],\n",
      "        [-0.0493]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4244], requires_grad=True)\n",
      "cost= tensor(0.1050, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 68\n",
      "w= tensor([[-0.7269],\n",
      "        [-0.3889],\n",
      "        [-0.0507]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4273], requires_grad=True)\n",
      "cost= tensor(0.1044, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 69\n",
      "w= tensor([[-0.7284],\n",
      "        [-0.3906],\n",
      "        [-0.0521]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4300], requires_grad=True)\n",
      "cost= tensor(0.1038, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 70\n",
      "w= tensor([[-0.7298],\n",
      "        [-0.3922],\n",
      "        [-0.0535]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4328], requires_grad=True)\n",
      "cost= tensor(0.1031, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 71\n",
      "w= tensor([[-0.7312],\n",
      "        [-0.3939],\n",
      "        [-0.0548]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4354], requires_grad=True)\n",
      "cost= tensor(0.1026, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 72\n",
      "w= tensor([[-0.7326],\n",
      "        [-0.3955],\n",
      "        [-0.0561]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4380], requires_grad=True)\n",
      "cost= tensor(0.1020, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 73\n",
      "w= tensor([[-0.7340],\n",
      "        [-0.3971],\n",
      "        [-0.0575]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4406], requires_grad=True)\n",
      "cost= tensor(0.1014, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 74\n",
      "w= tensor([[-0.7353],\n",
      "        [-0.3987],\n",
      "        [-0.0587]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4432], requires_grad=True)\n",
      "cost= tensor(0.1009, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 75\n",
      "w= tensor([[-0.7366],\n",
      "        [-0.4002],\n",
      "        [-0.0600]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4457], requires_grad=True)\n",
      "cost= tensor(0.1003, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 76\n",
      "w= tensor([[-0.7379],\n",
      "        [-0.4018],\n",
      "        [-0.0613]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4481], requires_grad=True)\n",
      "cost= tensor(0.0998, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 77\n",
      "w= tensor([[-0.7392],\n",
      "        [-0.4033],\n",
      "        [-0.0625]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4505], requires_grad=True)\n",
      "cost= tensor(0.0993, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 78\n",
      "w= tensor([[-0.7405],\n",
      "        [-0.4048],\n",
      "        [-0.0637]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4529], requires_grad=True)\n",
      "cost= tensor(0.0988, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 79\n",
      "w= tensor([[-0.7417],\n",
      "        [-0.4063],\n",
      "        [-0.0649]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4552], requires_grad=True)\n",
      "cost= tensor(0.0983, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 80\n",
      "w= tensor([[-0.7430],\n",
      "        [-0.4077],\n",
      "        [-0.0661]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4575], requires_grad=True)\n",
      "cost= tensor(0.0978, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 81\n",
      "w= tensor([[-0.7442],\n",
      "        [-0.4092],\n",
      "        [-0.0673]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4598], requires_grad=True)\n",
      "cost= tensor(0.0973, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 82\n",
      "w= tensor([[-0.7454],\n",
      "        [-0.4107],\n",
      "        [-0.0684]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4620], requires_grad=True)\n",
      "cost= tensor(0.0968, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 83\n",
      "w= tensor([[-0.7466],\n",
      "        [-0.4121],\n",
      "        [-0.0695]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4642], requires_grad=True)\n",
      "cost= tensor(0.0964, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 84\n",
      "w= tensor([[-0.7477],\n",
      "        [-0.4135],\n",
      "        [-0.0707]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4664], requires_grad=True)\n",
      "cost= tensor(0.0959, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 85\n",
      "w= tensor([[-0.7489],\n",
      "        [-0.4150],\n",
      "        [-0.0718]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4685], requires_grad=True)\n",
      "cost= tensor(0.0955, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 86\n",
      "w= tensor([[-0.7500],\n",
      "        [-0.4164],\n",
      "        [-0.0729]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4706], requires_grad=True)\n",
      "cost= tensor(0.0950, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 87\n",
      "w= tensor([[-0.7511],\n",
      "        [-0.4178],\n",
      "        [-0.0739]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4727], requires_grad=True)\n",
      "cost= tensor(0.0946, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 88\n",
      "w= tensor([[-0.7523],\n",
      "        [-0.4192],\n",
      "        [-0.0750]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4748], requires_grad=True)\n",
      "cost= tensor(0.0942, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 89\n",
      "w= tensor([[-0.7534],\n",
      "        [-0.4206],\n",
      "        [-0.0761]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4768], requires_grad=True)\n",
      "cost= tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 90\n",
      "w= tensor([[-0.7544],\n",
      "        [-0.4219],\n",
      "        [-0.0771]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4788], requires_grad=True)\n",
      "cost= tensor(0.0934, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 91\n",
      "w= tensor([[-0.7555],\n",
      "        [-0.4233],\n",
      "        [-0.0781]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4807], requires_grad=True)\n",
      "cost= tensor(0.0930, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 92\n",
      "w= tensor([[-0.7566],\n",
      "        [-0.4246],\n",
      "        [-0.0791]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4827], requires_grad=True)\n",
      "cost= tensor(0.0926, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 93\n",
      "w= tensor([[-0.7576],\n",
      "        [-0.4260],\n",
      "        [-0.0801]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4846], requires_grad=True)\n",
      "cost= tensor(0.0922, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 94\n",
      "w= tensor([[-0.7587],\n",
      "        [-0.4273],\n",
      "        [-0.0811]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4864], requires_grad=True)\n",
      "cost= tensor(0.0918, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 95\n",
      "w= tensor([[-0.7597],\n",
      "        [-0.4287],\n",
      "        [-0.0821]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4883], requires_grad=True)\n",
      "cost= tensor(0.0915, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 96\n",
      "w= tensor([[-0.7607],\n",
      "        [-0.4300],\n",
      "        [-0.0831]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4901], requires_grad=True)\n",
      "cost= tensor(0.0911, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 97\n",
      "w= tensor([[-0.7617],\n",
      "        [-0.4313],\n",
      "        [-0.0841]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4919], requires_grad=True)\n",
      "cost= tensor(0.0907, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 98\n",
      "w= tensor([[-0.7627],\n",
      "        [-0.4326],\n",
      "        [-0.0850]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4937], requires_grad=True)\n",
      "cost= tensor(0.0904, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n",
      "i= 99\n",
      "w= tensor([[-0.7637],\n",
      "        [-0.4339],\n",
      "        [-0.0860]], grad_fn=<SliceBackward0>)\n",
      "b= tensor([0.4955], requires_grad=True)\n",
      "cost= tensor(0.0900, grad_fn=<MeanBackward0>)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#반복하여 w, b를 찾음\n",
    "for i in range(100):\n",
    "    print(\"i=\", i)\n",
    "    print(\"w=\", w[:3])\n",
    "    print(\"b=\", b)\n",
    "\n",
    "    #리턴값이 0.5 미만은 0(악성), 0.5 이상은 1(양성)으로 분류\n",
    "    hypothesis = torch.sigmoid(torch.matmul(X_train, w) + b)\n",
    "\n",
    "    #오차를 계산해서 cost에 저장\n",
    "    cost = torch.mean(-y_train * torch.log(hypothesis) - (1 - y_train) * torch.log(1 - hypothesis))\n",
    "    print(\"cost=\", cost)\n",
    "\n",
    "    #cost를 이용하여 미분을 계산하고 w, b 업데이트\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8bf5eee-57b8-443d-bc65-fa35e6e1e0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.7549e-01],\n",
       "        [2.8698e-03],\n",
       "        [9.9624e-01],\n",
       "        [9.8876e-01],\n",
       "        [9.9531e-01],\n",
       "        [9.4487e-01],\n",
       "        [4.1872e-02],\n",
       "        [1.8481e-01],\n",
       "        [1.0132e-07],\n",
       "        [9.9837e-01],\n",
       "        [9.4996e-01],\n",
       "        [9.9935e-01],\n",
       "        [1.2367e-03],\n",
       "        [8.5746e-01],\n",
       "        [7.3909e-06],\n",
       "        [6.3315e-01],\n",
       "        [1.9548e-02],\n",
       "        [9.8079e-01],\n",
       "        [8.8045e-01],\n",
       "        [9.9265e-01],\n",
       "        [2.8408e-07],\n",
       "        [1.1884e-07],\n",
       "        [9.7660e-01],\n",
       "        [6.0178e-03],\n",
       "        [7.8836e-01],\n",
       "        [8.9105e-01],\n",
       "        [9.1999e-01],\n",
       "        [9.6206e-03],\n",
       "        [5.8337e-01],\n",
       "        [9.6045e-01],\n",
       "        [1.6701e-02],\n",
       "        [9.6629e-01],\n",
       "        [7.2700e-01],\n",
       "        [5.5087e-03],\n",
       "        [5.0356e-03],\n",
       "        [3.2857e-04],\n",
       "        [1.2930e-02],\n",
       "        [9.9373e-01],\n",
       "        [5.6000e-04],\n",
       "        [8.6540e-01],\n",
       "        [1.4513e-04],\n",
       "        [9.6744e-01],\n",
       "        [1.1252e-03],\n",
       "        [8.0009e-01],\n",
       "        [8.5079e-01],\n",
       "        [9.9771e-01],\n",
       "        [9.9558e-01],\n",
       "        [9.2847e-01],\n",
       "        [9.4258e-01],\n",
       "        [5.4141e-01],\n",
       "        [9.9949e-01],\n",
       "        [9.4952e-01],\n",
       "        [9.4076e-01],\n",
       "        [9.9713e-01],\n",
       "        [9.7280e-01],\n",
       "        [9.9837e-01],\n",
       "        [9.9159e-01],\n",
       "        [2.8999e-01],\n",
       "        [4.1801e-03],\n",
       "        [9.9232e-01],\n",
       "        [9.9757e-01],\n",
       "        [9.8900e-01],\n",
       "        [1.1207e-06],\n",
       "        [9.8763e-01],\n",
       "        [9.9610e-01],\n",
       "        [1.1426e-03],\n",
       "        [3.1793e-06],\n",
       "        [9.9991e-01],\n",
       "        [9.9997e-01],\n",
       "        [9.9957e-01],\n",
       "        [9.9945e-01],\n",
       "        [8.9508e-01],\n",
       "        [2.6254e-01],\n",
       "        [3.8988e-04],\n",
       "        [3.7982e-03],\n",
       "        [9.9966e-01],\n",
       "        [1.5725e-06],\n",
       "        [7.3403e-05],\n",
       "        [9.9758e-01],\n",
       "        [9.7531e-01],\n",
       "        [7.9456e-01],\n",
       "        [8.2946e-01],\n",
       "        [2.3305e-01],\n",
       "        [6.3872e-02],\n",
       "        [9.7993e-01],\n",
       "        [3.8666e-04],\n",
       "        [9.9154e-01],\n",
       "        [8.6351e-09],\n",
       "        [8.4583e-02],\n",
       "        [9.9949e-01],\n",
       "        [9.8348e-01],\n",
       "        [8.2772e-01],\n",
       "        [9.7369e-01],\n",
       "        [9.9836e-01],\n",
       "        [9.9515e-01],\n",
       "        [9.9814e-01],\n",
       "        [3.3770e-02],\n",
       "        [9.7945e-01],\n",
       "        [9.9348e-01],\n",
       "        [5.0870e-01],\n",
       "        [9.9930e-01],\n",
       "        [8.5068e-01],\n",
       "        [9.9155e-01],\n",
       "        [3.6923e-03],\n",
       "        [5.6451e-02],\n",
       "        [2.3447e-02],\n",
       "        [9.9318e-01],\n",
       "        [9.9423e-01],\n",
       "        [9.9958e-01],\n",
       "        [9.9180e-01],\n",
       "        [8.0492e-01],\n",
       "        [1.8012e-01],\n",
       "        [7.3052e-01],\n",
       "        [9.9317e-01]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = torch.sigmoid(torch.matmul(X_test, w) + b)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c818aaec-97af-42bf-97d8-669a62655e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict가 0.5 이상이면 1(양성), 미만이면 0(악성) 리턴\n",
    "predict01 = torch.where(predict >= 0.5, torch.tensor([1.]), torch.tensor([0.]))\n",
    "predict01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8708ad2e-7b18-454b-a3ae-1884f7e2f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실제 유방암 결과(y_test)와 예측값(predict01)이 같으면 True, 다르면 False 리턴\n",
    "acc01 = predict01.eq(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba77b776-d1b3-43e4-bff8-dc65ff7ca27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acc01에 저장된 값이 True면 1, False라면 0으로 변환\n",
    "acc02 = acc01.type(torch.DoubleTensor)\n",
    "acc02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f65ab3ba-d885-4b31-857b-b768d2d8c014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9649, dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acc02에 저장된 값을 모두 더한 후 전체 데이터 수로 나눔(평균을 구함)\n",
    "acc03 = torch.mean(acc02)\n",
    "acc03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bebec5d5-c5e6-4ee0-84d2-458878b4d215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.8312,  1.6324,  3.9907,  5.4532,  0.8753,  1.8759,  3.5362,\n",
       "         3.1806,  0.899 , -0.9087,  7.9715,  0.1713,  8.0943, 11.9829,\n",
       "         0.2529,  1.6661,  1.5853,  2.3802, -0.4427,  0.3207,  4.1694,\n",
       "         0.9339,  4.3981,  6.2228,  0.1643,  1.1448,  1.9777,  2.2735,\n",
       "        -0.4414, -0.5454]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#악성 암인지 양성 암인지 알고 싶은 환자의 유방암 정보\n",
    "X_arr = np.array([\n",
    "        [3.8312, 1.6324, 3.9907, 5.4532, 0.8753, 1.8759,\n",
    "         3.5362, 3.1806, 0.8990,-0.9087, 7.9715, 0.1713,\n",
    "         8.0943,11.9829, 0.2529, 1.6661, 1.5853, 2.3802,\n",
    "        -0.4427, 0.3207, 4.1694, 0.9339, 4.3981, 6.2228,\n",
    "         0.1643, 1.1448, 1.9777, 2.2735,-0.4414,-0.5454]\n",
    "    ])\n",
    "X_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f848a25-0fce-42fe-8031-5080b1205e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.99862879e+00, -5.49638886e+00, -4.04007624e+00,\n",
       "        -1.93383066e+00,  3.94161972e+03,  5.98363271e+02,\n",
       "         5.14884115e+02,  2.05218142e+03,  8.76334437e+02,\n",
       "        -1.98131337e+04,  1.11085273e+02, -5.60870550e+00,\n",
       "        -8.91853127e-03, -9.70534532e-01,  2.62148177e+04,\n",
       "         4.85940161e+03,  1.48001143e+03,  6.12079815e+04,\n",
       "        -6.37944936e+03,  4.59578113e+04, -3.97654096e+00,\n",
       "        -4.84283721e+00, -3.34450931e+00, -1.58351141e+00,\n",
       "         5.58779984e+01,  3.10155754e+01,  3.47295550e+01,\n",
       "         4.92520893e+02, -1.76993046e+02, -1.81750031e+03]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_arr을 학습데이터의 평균을 빼고 표준편차로 나눔\n",
    "X_arr = scaler.transform(X_arr)\n",
    "X_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10af3984-aa6d-4311-a0bb-3b836ebcab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.9986e+00, -5.4964e+00, -4.0401e+00, -1.9338e+00,  3.9416e+03,\n",
       "          5.9836e+02,  5.1488e+02,  2.0522e+03,  8.7633e+02, -1.9813e+04,\n",
       "          1.1109e+02, -5.6087e+00, -8.9185e-03, -9.7053e-01,  2.6215e+04,\n",
       "          4.8594e+03,  1.4800e+03,  6.1208e+04, -6.3794e+03,  4.5958e+04,\n",
       "         -3.9765e+00, -4.8428e+00, -3.3445e+00, -1.5835e+00,  5.5878e+01,\n",
       "          3.1016e+01,  3.4730e+01,  4.9252e+02, -1.7699e+02, -1.8175e+03]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_arr을 tensor 객체로 변환\n",
    "X_arr = torch.FloatTensor(X_arr)\n",
    "X_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fee7af9-28c1-4049-a4b5-206f32108951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#양성인지 악성인지 판별\n",
    "torch.sigmoid(torch.matmul(X_arr, w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea962e4-ee0a-4ee8-bcad-a26efaac6fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
